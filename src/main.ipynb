{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f378db07bb057f3a",
   "metadata": {},
   "source": [
    "# Comparação de Algoritmos de Aprendizado Supervisionado em Problemas de Classificação\n",
    "\n",
    "- Gabriel Peres de Souza\n",
    "- João Carlos dos Santos Correia\n",
    "- Rodrigo Macedo Júnior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c86b82052caf1",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7691a65d53079d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     Importação das bibliotecas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad3ca055f479c1e",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados\n",
    "O conjunto de dados utilizado neste estudo é o **\"Dodgers Loop Sensor\"**, obtido do repositório da UCI Machine Learning. O objetivo central é a classificação de dias em que ocorreram jogos de beisebol do time Dodgers, em Los Angeles, com base em dados de um sensor de contagem de veículos.\n",
    "\n",
    "Os dados foram coletados por um sensor de laço indutivo em uma rampa de acesso para uma rodovia, estrategicamente posicionada para capturar um sinal de tráfego sutil, que se manifesta principalmente como um aumento no fluxo de veículos ao final das partidas. As medições foram agregadas a cada 5 minutos ao longo de 25 semanas, resultando em um dataset rico para a análise de anomalias no fluxo de tráfego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d6159b0ca0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Carregamento e descrição da base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d77aa95cc594a",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados (se precisar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b5ad87298db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados faltantes, transformação de dados categóricos em numéricos,\n",
    "# escalas diferentes, outliers, dados desbalanceados, dados duplicados ou inconsistentes, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c300586fd72c861f",
   "metadata": {},
   "source": [
    "## Implementação dos algoritmos escolhidos\n",
    "Para este problema de classificação, foram selecionados dois algoritmos de aprendizado supervisionado com abordagens distintas para a criação de fronteiras de decisão: a Regressão Logística, implementada com o otimizador Gradiente Descendente Estocástico (SGD), e o k-Vizinhos Mais Próximos (k-NN). O objetivo é comparar seus desempenhos e determinar qual modelo é mais eficaz para detectar os eventos de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c61e727591b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descrição dos Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ac473d0631430",
   "metadata": {},
   "source": [
    "## 1º Algoritmo\n",
    "\n",
    "### Regressão Logística (treinada com Gradiente Descendente Estocástico)\n",
    "\n",
    "A Regressão Logística é um modelo linear que calcula diretamente a probabilidade de uma instância pertencer à classe positiva. Isso é feito através da função sigmoide, que mapeia qualquer valor real para o intervalo entre 0 e 1.\n",
    "\n",
    "Neste trabalho, os parâmetros do modelo são otimizados utilizando o **Gradiente Descendente Estocástico (SGD)**, um método eficiente para minimizar a função de perda logística (entropia cruzada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d235f633bc4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93994448e9657e11",
   "metadata": {},
   "source": [
    "## 2º Algorimo\n",
    "\n",
    "### k-Vizinhos Mais Próximos (k-NN)\n",
    "\n",
    "O k-NN é um algoritmo de aprendizado baseado em instâncias, também conhecido como \"lazy learner\", pois não constrói um modelo explícito durante o treinamento.\n",
    "\n",
    "Para classificar uma nova amostra, o k-NN calcula sua distância em relação a todas as amostras de treino. Em seguida, ele seleciona os *k* vizinhos mais próximos e a classificação é definida pela classe majoritária entre eles (votação). A eficácia do algoritmo depende criticamente da escolha do hiperparâmetro *k* e da métrica de distância utilizada (neste estudo, a distância Euclidiana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0ca97669f0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c694b8a71c6f8f",
   "metadata": {},
   "source": [
    "# Avaliação dos Modelos com métricas e grafos\n",
    "\n",
    "Para garantir que a avaliação do desempenho dos modelos seja robusta e generalize bem para dados não vistos, foi utilizada a técnica de **validação cruzada k-fold estratificada com k=10**.\n",
    "\n",
    "O desempenho foi medido utilizando um conjunto abrangente de métricas derivadas da matriz de confusão, conforme trabalhado em aula:\n",
    "- **Acurácia**: Percentual total de classificações corretas.\n",
    "- **Precisão**: Dentre todas as previsões de \"evento\", quantas estavam corretas.\n",
    "- **Revocação (Recall)**: De todos os \"eventos\" reais, quantos o modelo conseguiu identificar.\n",
    "- **F1-Score**: Média harmônica entre precisão e revocação, útil para dados desbalanceados.\n",
    "- **Curva ROC e AUC**: A Área Sob a Curva ROC (AUC) mede a capacidade do modelo de distinguir entre as classes, independentemente do limiar de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faadf3c36876ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembre-se de utilizar validação cruzada para divisão\n",
    "# do conjunto de dados e métricas adequadas ao problema de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ccb0669181efc",
   "metadata": {},
   "source": [
    "# Discussão dos resultados\n",
    "### Análise e Discussão dos Resultados\n",
    "\n",
    "A análise comparativa dos modelos revelou uma clara superioridade do k-NN para este problema de classificação.\n",
    "\n",
    "#### Desempenho Geral\n",
    "O modelo **k-NN demonstrou ser superior em quase todas as métricas**, incluindo acurácia (97,37%), precisão (78,44%), f1-score (75,92%) e AUC (0.980). Em contraste, a Regressão Logística (SGD) obteve um desempenho notavelmente inferior na maioria dessas métricas, embora tenha apresentado uma revocação mais alta.\n",
    "\n",
    "#### Análise do k-NN\n",
    "Com a configuração otimizada de **k=5** e utilizando a distância Euclidiana, o k-NN provou ser um classificador não apenas preciso, mas também bem balanceado. Suas métricas de precisão e revocação (73,55%) são equilibradas, o que o torna um modelo robusto e confiável para a aplicação prática de detecção de eventos. A análise da matriz de confusão mostra que ele classificou corretamente a grande maioria das instâncias, com um número baixo de falsos positivos e falsos negativos.\n",
    "\n",
    "#### Análise da Regressão Logística (SGD)\n",
    "O modelo de Regressão Logística apresentou um comportamento desequilibrado. Embora tenha alcançado uma **revocação altíssima de 87,18%**, identificando a maioria dos jogos que realmente ocorreram, isso veio ao custo de uma **precisão extremamente baixa de apenas 14,06%**. Na prática, isso significa que o modelo gerou um número excessivo de alarmes falsos (15.129 falsos positivos), o que limita severamente sua utilidade em um cenário real onde o custo de um falso alarme é relevante. O baixo f1-score (24,22%) reflete essa falta de equilíbrio.\n",
    "\n",
    "#### Conclusão da Análise\n",
    "A Curva ROC confirma a superioridade do k-NN, que obteve um **AUC de 0.980**, muito próximo do ideal 1.0, indicando uma excelente capacidade de discriminação entre as classes. O SGD, com um AUC de 0.814, embora bom, foi significativamente inferior\n",
    "\n",
    "Conclui-se que a capacidade do **k-NN de capturar padrões locais e não lineares nos dados foi fundamental para seu sucesso**. A Regressão Logística, por ser um modelo linear, não conseguiu modelar a complexa relação entre o fluxo de tráfego e a ocorrência de jogos com a mesma eficácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c09fdca13047fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6feec",
   "metadata": {},
   "source": [
    "## Metodologia\n",
    " \n",
    "Nesta seção, detalhamos o processo adotado para comparar algoritmos de classificação supervisionada, com foco em Regressão Logística (SGD) e k-Vizinhos Mais Próximos (k-NN). O objetivo é avaliar o desempenho dos modelos em um conjunto de dados real, utilizando validação rigorosa e métricas variadas.\n",
    " \n",
    "**Algoritmos utilizados:**\n",
    "- **Regressão Logística (SGDClassifier, loss='log_loss')**: Algoritmo linear, eficiente para grandes volumes de dados e robusto a ruídos. Utiliza gradiente descendente estocástico para otimização.\n",
    "- **k-Vizinhos Mais Próximos (k-NN)**: Algoritmo não paramétrico que considera a proximidade entre exemplos para realizar a classificação. Foram testados diferentes valores de *k* e métricas de distância para encontrar a melhor configuração.\n",
    " \n",
    "**Engenharia de atributos:**\n",
    "A partir das variáveis originais `Date` e `Time`, foram extraídos diversos atributos temporais: ano, mês, dia, dia da semana, dia do ano, hora, minuto, minutos desde meia-noite e indicador de fim de semana. O atributo `Count` foi mantido, e o alvo de classificação é o evento `Event` (binário: 0/1).\n",
    " \n",
    "**Validação e métricas:**\n",
    "Para garantir uma avaliação robusta, foi utilizada **validação cruzada k-fold (k=10)**, permitindo estimativas mais confiáveis do desempenho dos modelos. As métricas reportadas incluem:\n",
    "- **Acurácia**: Proporção de acertos totais.\n",
    "- **Precisão**: Proporção de positivos previstos que são realmente positivos.\n",
    "- **Sensibilidade (Recall)**: Proporção de positivos reais corretamente identificados.\n",
    "- **F1-score**: Média harmônica entre precisão e recall.\n",
    "- **ROC e AUC**: Curva ROC e área sob a curva, avaliando a capacidade de separação dos modelos.\n",
    " \n",
    "## Dados TODO Peres\n",
    " \n",
    "A descrição detalhada dos dados será incluída posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ff981",
   "metadata": {},
   "source": [
    "## Execução dos scripts\n",
    " \n",
    "- `sgd_logreg.py`: executa a análise com regressão logística (SGD)\n",
    "- `knn_model.py`: executa a análise com KNN (grid reduzido)\n",
    "- `test_models.py`: executa ambos e salva os resultados em JSON\n",
    "- `compare_plots.py`: gera gráficos comparativos (barras e ROC)\n",
    " \n",
    "Os dados gerados ficam em `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4642177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa os scripts principais para treinar e avaliar os modelos\n",
    "%run python data/test_models.py\n",
    "%run python data/compare_plots.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bba32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "from IPython.display import Image, display\n",
    "with open('data/sgd_results.json') as f: sgd=json.load(f)\n",
    "with open('data/knn_results.json') as f: knn=json.load(f)\n",
    "metrics=['accuracy','precision','recall','f1','roc_auc']\n",
    "df=pd.DataFrame({'SGD (Regressão logística)':[sgd['metrics_point_on_full'][m] for m in metrics], 'KNN':[knn['metrics_point_on_full'][m] for m in metrics]}, index=metrics)\n",
    "display(df.style.format('{:.4f}'))\n",
    "display(Image(filename='data/metrics_comparison.png'))\n",
    "display(Image(filename='data/roc_both.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega e exibe a comparação dos resultados dos modelos\n",
    "import json, pandas as pd\n",
    "from IPython.display import Image, display\n",
    "with open('data/sgd_results.json') as f: sgd=json.load(f)\n",
    "with open('data/knn_results.json') as f: knn=json.load(f)\n",
    "metrics=['accuracy','precision','recall','f1','roc_auc']\n",
    "df=pd.DataFrame({'SGD (Regressão logística)':[sgd['metrics_point_on_full'][m] for m in metrics], 'KNN':[knn['metrics_point_on_full'][m] for m in metrics]}, index=metrics)\n",
    "display(df.style.format('{:.4f}'))\n",
    "display(Image(filename='data/metrics_comparison.png'))\n",
    "display(Image(filename='data/roc_both.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
